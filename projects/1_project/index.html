<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Trajectory Prediction | Madhusudan Agarwal </title> <meta name="author" content="Madhusudan Agarwal"> <meta name="description" content="Deep learning-based trajectory prediction using Agroverse 2 dataset."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://hero1601.github.io/projects/1_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Madhusudan</span> Agarwal </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Trajectory Prediction</h1> <p class="post-description">Deep learning-based trajectory prediction using Agroverse 2 dataset.</p> </header> <article> <p>This project was built as part of the <strong>Trajectory Prediction Challenge</strong> using the <a href="https://www.argoverse.org/av2.html" rel="external nofollow noopener" target="_blank">Argoverse 2 Motion Forecasting Dataset</a>. The competition focused on developing models capable of accurately predicting the future trajectories of diverse road agents (vehicles, pedestrians, cyclists, buses, motorcycles, etc.) in complex, real-world driving scenarios.</p> <p>We used a modified version of Argoverse 2, with each scenario containing <strong>11 seconds of birdâ€™s-eye-view data</strong> sampled at <strong>10Hz</strong>, including agent centroid and heading. The model predicts future trajectories in challenging urban environments with long-range interactions and social complexity.</p> <p><a href="https://github.com/hero1601/trajectory-prediction" rel="external nofollow noopener" target="_blank">ðŸ”— View the code on GitHub</a></p> <hr> <h3 id="project-goals">Project Goals</h3> <ul> <li>Develop an accurate, generalizable motion forecasting model.</li> <li>Handle rare events, non-linear motion, and interaction-heavy scenes.</li> <li>Contribute to safe and interpretable <strong>autonomous vehicle planning</strong>.</li> </ul> <hr> <h3 id="dataset">Dataset</h3> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/input_heatmap-480.webp 480w,/assets/img/input_heatmap-800.webp 800w,/assets/img/input_heatmap-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/input_heatmap.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Input Dataset Visualization" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/output_heatmap-480.webp 480w,/assets/img/output_heatmap-800.webp 800w,/assets/img/output_heatmap-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/output_heatmap.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Output Dataset Visualization" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Visualization of trajectories in the Agroverse 2 dataset. </div> <ul> <li> <strong>Dataset</strong>: Argoverse 2 Motion Forecasting (Modified)</li> <li> <strong>Scenarios</strong>: 11s per agent, sampled at 10Hz</li> <li> <strong>Agents</strong>: Buses, motorcycles, pedestrians, cars, etc.</li> <li> <strong>Features</strong>: <ul> <li>Birdâ€™s-eye-view positions (x, y) and heading</li> <li>Social and temporal context</li> <li>Long-range prediction targets</li> <li>Multi-modal output</li> </ul> </li> </ul> <hr> <h3 id="model-overview">Model Overview</h3> <p>We designed a custom LSTM-based architecture that:</p> <ul> <li> <strong>Encodes</strong> each agentâ€™s trajectory with an LSTM</li> <li> <strong>Pools</strong> surrounding agents using a <strong>learned attention mechanism</strong> </li> <li> <strong>Combines</strong> ego and social context features</li> <li> <strong>Predicts</strong> the entire 60-step trajectory in one forward pass</li> </ul> <p>This approach proved to be more interpretable and stable than Transformer-based baselines, especially under limited compute.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/model-diagram-480.webp 480w,/assets/img/model-diagram-800.webp 800w,/assets/img/model-diagram-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/model-diagram.png" class="img-fluid rounded z-depth-1 w-50" width="100%" height="auto" title="Model Architecture" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption" style="text-align: center"> Our best-performing model encodes temporal and social context to predict future motion. </div> <hr> <h3 id="experiments--results">Experiments &amp; Results</h3> <p>We evaluated multiple baselines:</p> <ul> <li> <strong>Linear Regression</strong> â€” poor generalization</li> <li> <strong>MLP</strong> â€” handled nonlinearities but lacked temporal awareness</li> <li> <strong>LSTM</strong> â€” strong performance on ego-only data</li> <li> <strong>SocialLSTM</strong> â€” added multi-agent context</li> <li> <strong>My Model</strong> â€” achieved <strong>best performance</strong> via attention and feature augmentation</li> </ul> <table> <thead> <tr> <th>Model Variant</th> <th>Validation MSE</th> </tr> </thead> <tbody> <tr> <td>Full Model (w/ attention, features)</td> <td>7.7383</td> </tr> <tr> <td>Without Normalization</td> <td>423.1483</td> </tr> <tr> <td>Without Attention</td> <td>8.6116</td> </tr> <tr> <td>Without Augmentation</td> <td>9.5708</td> </tr> <tr> <td>Without Speed/Acceleration</td> <td>8.1191</td> </tr> </tbody> </table> <p><strong>Final metrics</strong>:</p> <ul> <li> <strong>MAE</strong>: 1.2879</li> <li> <strong>MSE</strong>: 7.7383</li> </ul> <hr> <h3 id="predictions">Predictions</h3> <p>After training the model, the final validation mean absolute error (MAE) was 1.2879, validation mean squared error (MSE) was 7.7383, and validation normalized MSE was 0.1579. These metrics indicate that the model performs well on the validation set and is likely to generalize effectively to unseen data.</p> <p>On Looking at the qualitative results of the models, it was observed that the modelâ€™s accuracy will vary depending on the nature of the ground truth trajectory. When the trajectory is a linear path such as Sample 1701 (shown in Figure), the model predicts it very accurately. However, when the ground truth trajectory involves more erratic or complex behavior, such as suddenly turning or stopping, as shown in Samples 49, 1368, and 1043, the model is much less accurate in its prediction.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prediction-480.webp 480w,/assets/img/prediction-800.webp 800w,/assets/img/prediction-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/prediction.png" class="img-fluid rounded z-depth-1 w-75" width="100%" height="auto" title="Prediction" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption" style="text-align: center"> Visualizations of predicted trajectories (in red) compared to ground truth paths (in blue) on test sequences. </div> <hr> <h3 id="key-takeaways">Key Takeaways</h3> <ul> <li> <strong>Normalization</strong> around the ego vehicle is essential for generalization.</li> <li> <strong>Social context</strong> improves prediction quality, especially in crowded or interactive scenes.</li> <li> <strong>Attention mechanisms</strong> outperform rigid social pooling.</li> <li> <strong>Feature engineering</strong> (e.g., speed &amp; acceleration) meaningfully boosts performance.</li> </ul> <hr> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> Â© Copyright 2025 Madhusudan Agarwal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>